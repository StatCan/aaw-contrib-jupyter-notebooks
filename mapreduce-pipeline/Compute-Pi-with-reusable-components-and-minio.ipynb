{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difficulty: Intermediate**\n",
    "\n",
    "# Summary:\n",
    "\n",
    "This example demonstrates how to build a pipeline from a mix of:\n",
    "* lightweight components (functions defined here in Python code and built into components)\n",
    "* off-the-shelf reusable components (defined by someone else and accessed directly from github)\n",
    "\n",
    "In doing this, we build a **shareable** pipeline - one that you can share with others and they can rerun on a new problem without needing this notebook.\n",
    "\n",
    "In particular, we use off-the-shelf components to enable our pipeline to write data to MinIO without needing to know how the MinIO Python package/CLI works.\n",
    "\n",
    "This example builds on concepts from a few others - see those notebooks for more detail: \n",
    "* The problem solved here is from [Compute Pi](../mapreduce-pipeline/Compute-Pi.ipynb) \n",
    "* We use lightweight components, which have some important [quirks](../kfp-basics/demo_kfp_lightweight_components.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:31.031867Z",
     "iopub.status.busy": "2021-07-05T22:36:31.031701Z",
     "iopub.status.idle": "2021-07-05T22:36:31.034836Z",
     "shell.execute_reply": "2021-07-05T22:36:31.034356Z",
     "shell.execute_reply.started": "2021-07-05T22:36:31.031846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl, compiler\n",
    "from kfp.components import func_to_container_op\n",
    "from kfp.components import load_component_from_file\n",
    "\n",
    "# TODO: Move utilities to a central repo\n",
    "from utilities import get_minio_credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "\n",
    "Our task is to compute an estimate of Pi by:\n",
    "1. picking some random points\n",
    "1. evaluating whether the points are inside a unit circle\n",
    "1. aggregating (2) to estimate pi\n",
    "\n",
    "Our solution to this task here focuses on:\n",
    "* making a fully reusable pipeline:\n",
    "    * The pipeline should be sharable.  You should be able to share the pipeline by giving them the pipeline.yaml file **without** sharing this notebook\n",
    "    * All user inputs are adjustable at runtime (no editing the YAML, changing hard-coded settings in the Python code, etc.)\n",
    "* persisting data in MinIO\n",
    "* using existing, reusable components where possible\n",
    "    * Ex: rather than teach our sample function to store results in MinIO, we use an existing component to store results\n",
    "    * This helps improve testability and reduces work when building new pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline pseudocode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve our problem, we need to: \n",
    "* Generate N random seeds\n",
    "    * For each random seed, do a sample step\n",
    "    * For each sample step, store the result to a location in MinIO\n",
    "* Collect all sample results\n",
    "* Compute pi (by averaging the results)\n",
    "* Save the final result to MinIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pseudocode our pipeline looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def compute_pi(n_samples: int,\n",
    "               output_location: str,\n",
    "               minio_credentials, \n",
    "              ):\n",
    "    seeds = create_seeds(n_samples)\n",
    "\n",
    "    for seed in seeds:\n",
    "        result = sample(seed)\n",
    "        copy_to_minio(minio_credentials, result, output_location)\n",
    "    \n",
    "    all_sample_results = collect_all_results(minio_credentials,\n",
    "                                             sample_output_location\n",
    "                                            )\n",
    "    \n",
    "    final_result = average(all_sample_results)\n",
    "    \n",
    "    copy_to_minio(minio_credentials, final_result, output_location)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we've pulled anything the user might want to set at runtime (the number of samples, the location in MinIO for results to be placed, and their MinIO credentials) out as pipeline arguments.\n",
    "\n",
    "Now lets fill in all the function calls with components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Components for our specific Business Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any operation that is specific to our problem (for example, how we train a model, how we transform a data file, ...) we need a component that does our specific task.  These are defined below.\n",
    "\n",
    "**NOTE:** We define the component Python code here, but you could pull these from .py files or elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our random seeds, we define a component that takes n_samples list of n_samples seeds.  The seeds here are arbitrary (although we've defined them such that they will be unique and reproducible).\n",
    "\n",
    "While it might feel like we could simply do this in `compute_pi()`: \n",
    "```\n",
    "seeds = [i for i in range(n_samples)]\n",
    "```\n",
    "we cannot because n_samples is a pipeline runtime argument.  When we run this notebook to define the pipeline, n_samples is a **placeholder** rather than an actual integer.  Thus, the generation of samples must occur at pipeline runtime rather than in the pipeline definition itself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:31.452383Z",
     "iopub.status.busy": "2021-07-05T22:36:31.452136Z",
     "iopub.status.idle": "2021-07-05T22:36:31.455904Z",
     "shell.execute_reply": "2021-07-05T22:36:31.455223Z",
     "shell.execute_reply.started": "2021-07-05T22:36:31.452358Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_seeds_func(n_samples: int) -> list:\n",
    "    \"\"\"\n",
    "    Creates n_samples seeds and returns as a list\n",
    "\n",
    "    Note: When used as an operation in a KF pipeline, the list is serialized\n",
    "    to a string.  Can deserialize with strip and split or json package\n",
    "    This sort of comma separated list will work natively with KF Pipelines'\n",
    "    parallel for (we can feed this directly into a parallel for loop and it\n",
    "    breaks into elements for us)\n",
    "\n",
    "    \"\"\"\n",
    "    constant = 10  # just so I know something is happening\n",
    "    return [constant + i for i in range(n_samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By defining this function in Python first, we can test it here to make sure it works as expected (rigorous testing omitted here, but recommended for your own tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:31.889290Z",
     "iopub.status.busy": "2021-07-05T22:36:31.889055Z",
     "iopub.status.idle": "2021-07-05T22:36:31.892401Z",
     "shell.execute_reply": "2021-07-05T22:36:31.891875Z",
     "shell.execute_reply.started": "2021-07-05T22:36:31.889267Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "# Very rigorous testing!\n",
    "print(create_seeds_func(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can then convert our tested function to a task constructor using `func_to_container_op`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:32.272896Z",
     "iopub.status.busy": "2021-07-05T22:36:32.272646Z",
     "iopub.status.idle": "2021-07-05T22:36:32.276664Z",
     "shell.execute_reply": "2021-07-05T22:36:32.276109Z",
     "shell.execute_reply.started": "2021-07-05T22:36:32.272872Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This example notebook was executed using python 3.8.8\n",
      "Using base_image_python: python:3.8.8-buster\n"
     ]
    }
   ],
   "source": [
    "# Define the base image our code will run from.\n",
    "# This is reused in a few components\n",
    "import sys\n",
    "python_version_as_string = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "base_image_python = f\"python:{python_version_as_string}-buster\"\n",
    "print(f\"This example notebook was executed using python {python_version_as_string}\")\n",
    "print(f\"Using base_image_python: {base_image_python}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:32.453784Z",
     "iopub.status.busy": "2021-07-05T22:36:32.453534Z",
     "iopub.status.idle": "2021-07-05T22:36:32.461092Z",
     "shell.execute_reply": "2021-07-05T22:36:32.460528Z",
     "shell.execute_reply.started": "2021-07-05T22:36:32.453759Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_seeds_op = func_to_container_op(create_seeds_func,\n",
    "                                       base_image=base_image_python,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task constructor `create_seeds_op` is what actually creates instances of these components in our pipeline.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, we a sample function and corresponding task constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:33.150701Z",
     "iopub.status.busy": "2021-07-05T22:36:33.150450Z",
     "iopub.status.idle": "2021-07-05T22:36:33.155991Z",
     "shell.execute_reply": "2021-07-05T22:36:33.155483Z",
     "shell.execute_reply.started": "2021-07-05T22:36:33.150678Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_func(seed: int) -> NamedTuple('Outputs', [('x', float), ('y', float), ('result', int), ('seed', int)]):\n",
    "    \"\"\"\n",
    "    Define the \"sample\" pipeline operation\n",
    "\n",
    "    Args:\n",
    "        seed (int): Integer seed used for random calculation\n",
    "\n",
    "    Returns:\n",
    "        The result of this operation will be a named tuple with:\n",
    "        {\n",
    "             \"x\" : x-coordinate,\n",
    "             \"y\" : y-coordinate,\n",
    "             \"result\" : 4 if in unit-circle, 0 otherwise,\n",
    "             \"seed\" : the input seed value,\n",
    "        }\n",
    "    \"\"\"\n",
    "    from collections import namedtuple\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "\n",
    "    print(\"Pick random point\")\n",
    "    # x,y ~ Uniform([-1,1])\n",
    "    x = random.random() * 2 - 1\n",
    "    y = random.random() * 2 - 1\n",
    "    print(f\"Sample selected: ({x}, {y})\")\n",
    "\n",
    "    if (x ** 2 + y ** 2) <= 1:\n",
    "        print(f\"Random point is inside the unit circle\")\n",
    "        result = 4\n",
    "    else:\n",
    "        print(f\"Random point is outside the unit circle\")\n",
    "        result = 0\n",
    "    # Return output in the same structure as defined in the NamedTuple type hint\n",
    "    output_spec = namedtuple(\"output\", (\"x\", \"y\", \"result\", \"seed\"))\n",
    "    output = output_spec(x, y, result, seed)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:33.326287Z",
     "iopub.status.busy": "2021-07-05T22:36:33.326035Z",
     "iopub.status.idle": "2021-07-05T22:36:33.328887Z",
     "shell.execute_reply": "2021-07-05T22:36:33.328376Z",
     "shell.execute_reply.started": "2021-07-05T22:36:33.326261Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (insert your testing here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:33.507200Z",
     "iopub.status.busy": "2021-07-05T22:36:33.506944Z",
     "iopub.status.idle": "2021-07-05T22:36:33.519903Z",
     "shell.execute_reply": "2021-07-05T22:36:33.519234Z",
     "shell.execute_reply.started": "2021-07-05T22:36:33.507173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_op = func_to_container_op(sample_func,\n",
    "                                 base_image=base_image_python,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:33.869049Z",
     "iopub.status.busy": "2021-07-05T22:36:33.868811Z",
     "iopub.status.idle": "2021-07-05T22:36:33.872605Z",
     "shell.execute_reply": "2021-07-05T22:36:33.871876Z",
     "shell.execute_reply.started": "2021-07-05T22:36:33.869027Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_func(numbers) -> float:\n",
    "    \"\"\"\n",
    "    Computes the average value of a JSON list of numbers, returned as a float\n",
    "    \"\"\"\n",
    "    import json\n",
    "    print(numbers)\n",
    "    print(type(numbers))\n",
    "    numbers = json.loads(numbers)\n",
    "    return sum(numbers) / len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:34.046643Z",
     "iopub.status.busy": "2021-07-05T22:36:34.046389Z",
     "iopub.status.idle": "2021-07-05T22:36:34.049407Z",
     "shell.execute_reply": "2021-07-05T22:36:34.048704Z",
     "shell.execute_reply.started": "2021-07-05T22:36:34.046619Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (and even more testing here!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:34.229801Z",
     "iopub.status.busy": "2021-07-05T22:36:34.229524Z",
     "iopub.status.idle": "2021-07-05T22:36:34.237168Z",
     "shell.execute_reply": "2021-07-05T22:36:34.236541Z",
     "shell.execute_reply.started": "2021-07-05T22:36:34.229774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_op = func_to_container_op(average_func,\n",
    "                                  base_image=base_image_python,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Reusable Components for the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any generic operations in our pipeline, we can reuse components that were defined by others.  In particular, interactions with MinIO here are good candidates for generic, reusable components.  \n",
    "\n",
    "Reusable components can be loaded directly from compiled yaml files - we just have to point to them.  Think of them roughly as imported functions.  They can come from local text files, or be imported directly from github/internet.  \n",
    "\n",
    "These yaml files are approachable - open them up to see how they work!\n",
    "\n",
    "**TODO: Move reusables to github**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:34.854918Z",
     "iopub.status.busy": "2021-07-05T22:36:34.854647Z",
     "iopub.status.idle": "2021-07-05T22:36:34.877331Z",
     "shell.execute_reply": "2021-07-05T22:36:34.876799Z",
     "shell.execute_reply.started": "2021-07-05T22:36:34.854890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Component that takes a file and puts it into minio\n",
    "copy_to_minio_op = load_component_from_file('./components/copy_to_minio.yaml')\n",
    "\n",
    "# Component that does an \"mc find\" operation, finding files in minio that \n",
    "# match a pattern\n",
    "mc_find_op = load_component_from_file('./components/minio_find.yaml')\n",
    "\n",
    "# Component that takes a list of files and concatenates their contents to a JSON\n",
    "# list\n",
    "mc_cat_files_to_json_op = load_component_from_file('./components/minio_cat_files_to_json.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Compile Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our component constructors defined, we build our full pipeline.  Remember that while we use a Python function to define our pipeline here, anything that depends on a KFP-specific entity (an input argument, a component result, etc) is computed at runtime in kubernetes.  This means we can't do things like \n",
    "```\n",
    "for seed in seeds:\n",
    "    sample_op = sample_op(seed)\n",
    "```\n",
    "because Python would try to interpret seeds, which is a *placeholder* object for a future value, as an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:35.519365Z",
     "iopub.status.busy": "2021-07-05T22:36:35.519137Z",
     "iopub.status.idle": "2021-07-05T22:36:35.525968Z",
     "shell.execute_reply": "2021-07-05T22:36:35.525424Z",
     "shell.execute_reply.started": "2021-07-05T22:36:35.519341Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Estimate Pi w/Minio\",\n",
    "    description=\"Extension of the Map-Reduce example using dynamic number of samples and Minio for storage\"\n",
    ")\n",
    "def compute_pi(n_samples: int, output_location: str, minio_url,\n",
    "               minio_access_key: str, minio_secret_key: str):\n",
    "    seeds = create_seeds_op(n_samples)\n",
    "\n",
    "    # We add the KFP RUN_ID here in the output location so that we don't\n",
    "    # accidentally overwrite another run.  There's lots of ways to manage\n",
    "    # data, this is just one possibility.\n",
    "    this_run_output_location = f\"{str(output_location).rstrip('/')}\" \\\n",
    "                               f\"/{kfp.dsl.RUN_ID_PLACEHOLDER}\"\n",
    "\n",
    "    sample_output_location = f\"{this_run_output_location}/seeds\"\n",
    "\n",
    "    copy_ops = []\n",
    "    with kfp.dsl.ParallelFor(seeds.output) as seed:\n",
    "        sample_op_ = sample_op(seed)\n",
    "\n",
    "        # NOTE: A current limitation of the ParallelFor loop in KFP is that it\n",
    "        # does not give us an easy way to collect the results afterwards.  To\n",
    "        # get around this problem, we store results in a known place in minio\n",
    "        # and later glob the result files back out\n",
    "        #\n",
    "        # Save the result from this sample to minio in\n",
    "        # ./seeds/{seed}/result.out.  We save with {seed} in the filepath to\n",
    "        # prevent different paths from otherwriting each other.  Note that\n",
    "        # this relies on seed being unique\n",
    "        #\n",
    "        # TODO: Could we do an append-to-file-in-minio and concatenate them \n",
    "        # on the fly? Would minio have issues with simultaneous writes?\n",
    "        copy_sample = copy_to_minio_op(\n",
    "            minio_url,\n",
    "            minio_access_key,\n",
    "            minio_secret_key,\n",
    "            sample_op_.outputs['result'],\n",
    "            f\"{sample_output_location}{seed}/result.out\",\n",
    "        )\n",
    "\n",
    "        # Make a list of copy_ops so we can do result collection after they finish\n",
    "        copy_ops.append(copy_sample)\n",
    "\n",
    "    # Collect all result.out files in the sample_output_location and concatenate\n",
    "    # their contents as a json list\n",
    "    search_pattern = r'/result.out'\n",
    "    files_to_cat = mc_find_op(\n",
    "        minio_url,\n",
    "        minio_access_key,\n",
    "        minio_secret_key,\n",
    "        sample_output_location,\n",
    "        search_pattern,\n",
    "    )\n",
    "\n",
    "    # files_to_cat requires all sample_ops to be done before running (all\n",
    "    # results must be generated first).  Enforce this by setting files_to_cat\n",
    "    # to be .after() all copy_op tasks\n",
    "    for op in copy_ops:\n",
    "        files_to_cat.after(op)\n",
    "\n",
    "    all_samples = mc_cat_files_to_json_op(\n",
    "        minio_url,\n",
    "        minio_access_key,\n",
    "        minio_secret_key,\n",
    "        files_to_cat.output,\n",
    "    )\n",
    "\n",
    "    final_result = average_op(all_samples.output)\n",
    "\n",
    "    copy_average = copy_to_minio_op(\n",
    "        minio_url,\n",
    "        minio_access_key,\n",
    "        minio_secret_key,\n",
    "        final_result.output,\n",
    "        f\"{this_run_output_location}/result.out\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile our pipeline into a reusable YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:35.983641Z",
     "iopub.status.busy": "2021-07-05T22:36:35.983348Z",
     "iopub.status.idle": "2021-07-05T22:36:36.077482Z",
     "shell.execute_reply": "2021-07-05T22:36:36.076836Z",
     "shell.execute_reply.started": "2021-07-05T22:36:35.983614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported pipeline definition to compute-pi-with-reusables.zip\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"compute-pi-with-reusables\"\n",
    "experiment_yaml_zip = experiment_name + '.zip'\n",
    "compiler.Compiler().compile(\n",
    "    compute_pi,\n",
    "    experiment_yaml_zip\n",
    ")\n",
    "print(f\"Exported pipeline definition to {experiment_yaml_zip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our above pipeline definition to do our task.  Note that anything below here can be done **without** the above code.  All we need is the yaml file from the last step.  We can even do this from the Kubeflow Pipelines UI or from a terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings\n",
    "Update the next block to match your own setup.  bucket will be your namespace (likely your firstname-lastname), and output_location is where inside the bucket you want to put your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:55.869890Z",
     "iopub.status.busy": "2021-07-05T22:36:55.869636Z",
     "iopub.status.idle": "2021-07-05T22:36:55.873015Z",
     "shell.execute_reply": "2021-07-05T22:36:55.872475Z",
     "shell.execute_reply.started": "2021-07-05T22:36:55.869858Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "bucket = os.environ['NB_NAMESPACE']\n",
    "# Python Minio SDK expects bucket and output_location to be separate\n",
    "output_location = bucket + \"/map-reduce-output\"\n",
    "n_samples = 10\n",
    "minio_tenant = \"standard\"  # probably can leave this as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:36:57.497288Z",
     "iopub.status.busy": "2021-07-05T22:36:57.497043Z",
     "iopub.status.idle": "2021-07-05T22:36:57.501924Z",
     "shell.execute_reply": "2021-07-05T22:36:57.501331Z",
     "shell.execute_reply.started": "2021-07-05T22:36:57.497263Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to access minio credentials from:\n",
      "/vault/secrets/minio-standard-tenant-1.json\n",
      "Trying to access minio credentials from:\n",
      "/vault/secrets/minio-standard-tenant-1.json\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10\n",
    "\n",
    "# Get minio credentials using a helper\n",
    "minio_settings = get_minio_credentials(minio_tenant, strip_http=False)\n",
    "minio_url = minio_settings[\"url\"]\n",
    "minio_access_key = minio_settings[\"access_key\"]\n",
    "minio_secret_key = minio_settings[\"secret_key\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T22:37:06.773823Z",
     "iopub.status.busy": "2021-07-05T22:37:06.773518Z",
     "iopub.status.idle": "2021-07-05T22:37:07.590564Z",
     "shell.execute_reply": "2021-07-05T22:37:07.589820Z",
     "shell.execute_reply.started": "2021-07-05T22:37:06.773793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/_/pipeline/#/experiments/details/d8e8041c-1b6f-445e-a045-6b712b565a69\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/_/pipeline/#/runs/details/b7d6766a-132b-4b25-8007-86c067ca5902\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "result = client.create_run_from_pipeline_func(\n",
    "    compute_pi,\n",
    "    arguments={\"n_samples\": n_samples,\n",
    "               \"output_location\": output_location,\n",
    "               \"minio_url\": minio_url,\n",
    "               \"minio_access_key\": minio_access_key,\n",
    "               \"minio_secret_key\": minio_secret_key,\n",
    "               },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional)\n",
    "\n",
    "Wait for the run to complete, then print that it is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wait_result = result.wait_for_run_completion(timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-05T22:41:55.183790Z",
     "iopub.status.idle": "2021-07-05T22:41:55.184054Z",
     "shell.execute_reply": "2021-07-05T22:41:55.183942Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Run {wait_result.run.id}\\n\\tstarted at \\t{wait_result.run.created_at}\\n\\tfinished at \\t{wait_result.run.finished_at}\\n\\twith status {wait_result.run.status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
