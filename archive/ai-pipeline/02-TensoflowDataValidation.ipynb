{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Pipelines (0.2.5)\n",
    "\n",
    "We start by downloading a specific release of Kubeflow components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/kubeflow/pipelines/archive/0.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf 0.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_download_component = kfp.components.load_component_from_file(\n",
    "    \"pipelines-0.2.5/components/google-cloud/storage/download/component.yaml\")\n",
    "tfx_csv_gen = kfp.components.load_component_from_file(\n",
    "    \"pipelines-0.2.5/components/tfx/ExampleGen/CsvExampleGen/component.yaml\")\n",
    "tfx_statistic_gen = kfp.components.load_component_from_file(\n",
    "    \"pipelines-0.2.5/components/tfx/StatisticsGen/component.yaml\")\n",
    "tfx_schema_gen = kfp.components.load_component_from_file(\n",
    "    \"pipelines-0.2.5/components/tfx/SchemaGen/component.yaml\")\n",
    "tfx_example_validator = kfp.components.load_component_from_file(\n",
    "    \"pipelines-0.2.5/components/tfx/ExampleValidator/component.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "  name='DL',\n",
    "  description='Sample DL pipeline'\n",
    ")\n",
    "def pipeline_with_dl():\n",
    "    dl_op = gcs_download_component(gcs_path=\"gs://ml-pipeline-playground/tensorflow-tfx-repo/tfx/components/testdata/external/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(pipeline_with_dl, 'dl_pipeline.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experiment = client.create_experiment(name='dl')\n",
    "my_run = client.run_pipeline(my_experiment.id, 'dl', 'dl_pipeline.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "  name='TFDV',\n",
    "  description='TF DV Pipeline'\n",
    ")\n",
    "def tfdv_pipeline():\n",
    "    fetch = kfp.dsl.ContainerOp(\n",
    "      name='download',\n",
    "      image='busybox',\n",
    "      command=['sh', '-c'],\n",
    "      arguments=[\n",
    "          'sleep 1;'\n",
    "          'mkdir -p /tmp/data;'\n",
    "          'wget https://raw.githubusercontent.com/moorissa/medium/master/items-recommender/data/trx_data.csv -O /tmp/data/results.csv'],\n",
    "      file_outputs={'downloaded': '/tmp/data'})\n",
    "    records_example = tfx_csv_gen(input_base=fetch.output)\n",
    "    stats = tfx_statistic_gen(input_data=records_example.output)\n",
    "    schema_op = tfx_schema_gen(stats.output)\n",
    "    tfx_example_validator(stats=stats.outputs['output'], schema=schema_op.outputs['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(tfdv_pipeline, 'tfdv_pipeline.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experiment = client.create_experiment(name='tfdv_pipeline')\n",
    "my_run = client.run_pipeline(my_experiment.id, 'tfdv', 'tfdv_pipeline.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tfx tensorflow-data-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download your schema by looking at the inputs/outputs in your pipeline run for the schemagen stage.\n",
    "\n",
    "For your convenience this is also included in the config folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tfdv.load_schema_text(\"config/schema_info\")\n",
    "tfdv.display_schema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfx_transform = kfp.components.load_component_from_file(\"pipelines-0.2.5/components/tfx/Transform/component.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from minio import Minio\n",
    "\n",
    "minio_endpoint = os.environ.get('MINIO_URL', 'minio-service.kubeflow.svc.cluster.local:9000')\n",
    "minio_key = os.environ.get('MINIO_KEY', 'minio')\n",
    "minio_secret = os.environ.get('MINIO_SECRET', 'XXXXXX')\n",
    "minioClient = Minio(minio_endpoint,\n",
    "                    access_key=minio_key,\n",
    "                    secret_key=minio_secret,\n",
    "                    secure=False)\n",
    "\n",
    "print('Minio parameters : URL ', minio_endpoint, ' key ', minio_key, ' secret ', minio_secret)\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = minio_key\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = minio_secret\n",
    "os.environ['AWS_REGION'] = 'us-west-1'\n",
    "os.environ['S3_REGION'] = 'us-west-1'\n",
    "os.environ['S3_ENDPOINT'] = minio_endpoint\n",
    "os.environ['S3_USE_HTTPS'] = '0'\n",
    "os.environ['S3_VERIFY_SSL'] = '0'\n",
    "\n",
    "module_file=\"s3://data/test.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import kfp\n",
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from kubernetes import client as k8s_client \n",
    "\n",
    "@kfp.dsl.pipeline(\n",
    "  name='TFX',\n",
    "  description='TFX pipeline'\n",
    ")\n",
    "def tfx_pipeline():\n",
    "    fetch = kfp.dsl.ContainerOp(\n",
    "      name='download',\n",
    "      image='busybox',\n",
    "      command=['sh', '-c'],\n",
    "      arguments=[\n",
    "          'sleep 1;'\n",
    "          'mkdir -p /tmp/data;'\n",
    "          'wget https://raw.githubusercontent.com/moorissa/medium/master/items-recommender/data/trx_data.csv -O /tmp/data/results.csv'],\n",
    "      file_outputs={'downloaded': '/tmp/data'})\n",
    "    records_example = tfx_csv_gen(input_base=fetch.output)\n",
    "    stats = tfx_statistic_gen(input_data=records_example.output)\n",
    "    schema_op = tfx_schema_gen(stats.output)\n",
    "    tfx_example_validator(stats=stats.outputs['output'], schema=schema_op.outputs['output'])\n",
    "    transformed_output = tfx_transform(\n",
    "        input_data=records_example.output,\n",
    "        schema=schema_op.outputs['output'],\n",
    "        module_file=module_file) # Path to your TFT code on GCS/S3\n",
    "    dsl.get_pipeline_conf().set_image_pull_secrets([k8s_client.V1ObjectReference(name=\"k8scc01covidacr-registry-connection\")])\n",
    "    dsl.get_pipeline_conf().add_op_transformer(lambda cop: cop.container.add_env_variable(k8s_client.V1EnvVar(name='AWS_ACCESS_KEY_ID', value=os.environ['AWS_ACCESS_KEY_ID'])))\n",
    "    dsl.get_pipeline_conf().add_op_transformer(lambda cop: cop.container.add_env_variable(k8s_client.V1EnvVar(name='AWS_SECRET_ACCESS_KEY', value=os.environ['AWS_SECRET_ACCESS_KEY'])))\n",
    "    dsl.get_pipeline_conf().add_op_transformer(lambda cop: cop.container.add_env_variable(k8s_client.V1EnvVar(name='AWS_REGION', value=os.environ['AWS_REGION'])))\n",
    "    dsl.get_pipeline_conf().add_op_transformer(lambda cop: cop.container.add_env_variable(k8s_client.V1EnvVar(name='S3_REGION', value=os.environ['S3_REGION'])))\n",
    "    dsl.get_pipeline_conf().add_op_transformer(lambda cop: cop.container.add_env_variable(k8s_client.V1EnvVar(name='S3_ENDPOINT', value=os.environ['S3_ENDPOINT'])))\n",
    "    dsl.get_pipeline_conf().add_op_transformer(lambda cop: cop.container.add_env_variable(k8s_client.V1EnvVar(name='S3_USE_HTTPS', value=os.environ['S3_USE_HTTPS'])))\n",
    "    dsl.get_pipeline_conf().add_op_transformer(lambda cop: cop.container.add_env_variable(k8s_client.V1EnvVar(name='S3_VERIFY_SSL', value=os.environ['S3_VERIFY_SSL'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(tfx_pipeline, 'tfx_pipeline.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experiment = client.create_experiment(name='tfx_pipeline')\n",
    "my_run = client.run_pipeline(my_experiment.id, 'tfx', 'tfx_pipeline.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
